y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
## Calculate the mean, standard deviation, and sample size in order to calculate the lower and upper bounds of the confidence interval.
meanIQ <- sum(y)/length(y)
demeanedSum <- NULL
for(i in 1:length(y)){
demeanedSum[i] <- y[i] - meanIQ
}
squaredError <- demeanedSum^2
variance <- sum(squaredError)/(length(y) - 1)
sdIQ <- sqrt(variance)
z90 <- qt((1-.9)/2, 24)
lower_90 <- meanIQ + z90*sdIQ/sqrt(length(y))
upper_90 <- meanIQ - z90*sdIQ/sqrt(length(y))
confint90 <- c(lower_90, upper_90)
confint90
t.test(y, conf.level = 0.9)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
#confidence coefficient is 0.90
#using qtnorm because n is <30
library(msm)
lapply(c("msm"),  pkgTest)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
lapply(c("msm"),  pkgTest)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
z90 <- qtnorm((1-0.90)/2, lower.tail = FALSE)
n <- length(y)
sample_mean <- mean(y)
sample_sd <- sd(y)
lower_90 <- sample_mean - (z90 * (sample_sd/sqrt(n)))
upper_90 <- sample_mean + (z90 * (sample_sd/sqrt(n)))
confint90 <- c(lower_90, upper_90)
confint90
?qtnorm
#Taking Data set and pasting
problem_1 <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
mean(problem_1) #the sample mean for IQ score is 98.44
length(problem_1) # three are 25 observations by counselor on student IQ scores
sd(problem_1) # the standard deviation of the observations in IQ scores is 13.09
std_error <- sd(problem_1) / sqrt(length(problem_1)) #accounting standard deviation based on our sample size to obtain sample error
std_error # standard error is 2.62
sqrt(10)
qt(0.05,n−1,lower.tail=F)
qt(0.05,25−1,lower.tail=F)
qt(0.05,24,lower.tail=F)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
#calculate a test statistic
mean(y) #sample mean = 98.44
#population mean = 100
sd(y) #sd of sample = 13.09
13.09/sqrt(25) #standard deviation of sampling distribution = 2.618
(98.44-100)/2.618 #-0.5958747, df=24
SE<−sd(y)/sqrt(n)
# Step 2: Calculate the test statistic for this hypothesis testing of mean
t <− (mean(y) − 100)/SE
SE<-sd(y)/sqrt(n)
# Step 2: Calculate the test statistic for this hypothesis testing of mean
t <- (mean(y) -100)/SE
t
expenditure <- read.table("expenditure.txt", header=T)
# set working directory
setwd("~/GitHub/QTM200Spring2020/problem_sets/PS1")
# set working directory
setwd("~/Documents/GitHub/QTM200Spring2020/problem_sets/PS1")
<<<<<<< HEAD
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
##finding the confidnce interval
mean(y)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
##finding the confidnce interval
qnorm(0.95)
##finding the confidnce interval
tnorm(0.95)
##finding the confidnce interval
tqnorm(0.95)
<- mean(y)
s <- sd(y)
n <- 25
error <- qt(0.95, df=n-1)*s/sqrt(n)
m <- mean(y)
s <- sd(y)
n <- 25
error <- qt(0.95, df=n-1)*s/sqrt(n)
m <- mean(y)
s <- sd(y)
n <- 25
error <- qt(0.95, df=n-1)*s/sqrt(n)
left <- a-error
right <- a+error
left
right
error <- qt(0.95, df=n-1)*s/sqrt(n)
left <- a-error
left <- m-error
left
m <- mean(y)
s <- sd(y)
n <- 25
error <- qt(0.95, df=n-1)*s/sqrt(n)
left <- m-error
right <- m+error
left
right
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
source('~/GitHub/QTM200Spring2020/problem_sets/PS1/PS1 - answers.R')
#####################
# Problem 2
#####################
#Conducting a test with 0.05 significance level
#assumptions are: continous data, random sample, the sample size is bigger (shown through formula)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
#null hypothesis Ho: pi < pio
pio <- 100
pi <- mean(y)
t* <- qt(0.05, df=n-1)*s/sqrt(n)
t* <- qt(0.05, df=n-1)*s/sqrt(n)
ts <- qt(0.05, df=n-1)*s/sqrt(n)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
##finding the confidnce interval
#first the mean was found
m <- mean(y)
#then the standard deviation
s <- sd(y)
#n is the number of samples
n <- 25
#finding the error using t distribution as n is less than 30
error <- qt(0.95, df=n-1)*s/sqrt(n)
#left confidence interval
left <- m-error
#right confidence interval
right <- m+error
left
right
# the 90% CI is (93.96, 102.92)
#####################
# Problem 2
#####################
#Conducting a test with 0.05 significance level
#assumptions are: continous data, random sample, the sample size is bigger (shown through formula)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
#null hypothesis Ho: pi < pio
pio <- 100
pi <- mean(y)
ts <- qt(0.05, df=n-1)*s/sqrt(n)
p = pt(abs(ts), df=n-1, lower.tail=F)
p
ts
ts
ts <- qt(.95, df=n-1)*s/sqrt(n)
ts
p = pt(abs(ts), df=n-1, lower.tail=F)
p
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
expenditure <- read.table("expenditure.txt", header=T)
str(expenditure)
plot(Y~X)
expenditure <- read.table("expenditure.txt", header=T)
str(expenditure)
library(ggplot2)
library(diplyr)
library(tidyr)
install.packages(diplyr)
install.packages("tidyr")
install.packages("tidyr")
install.packages("diplyr")
expenditure <- read.table("expenditure.txt", header=T)
str(expenditure)
library(ggplot2)
library(diplyr)
library(tidyr)
expenditure <- read.table("expenditure.txt", header=T)
str(expenditure)
library(ggplot2)
library(dplyr)
library(tidyr)
View(expenditure)
ggplot(expenditure, aes(x=Region, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()+
facet_grid(~Region)
# set working directory
setwd("~/Documents/GitHub/QTM200Spring2020/problem_sets/PS1-answers")
setwd("~/GitHub/QTM200Spring2020/problem_sets/PS1")
ggplot(expenditure, aes(x=X1, y=Y, color=Region))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y, color=Region, shape=Region))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y, color=Region))+
geom_point()
X <- unite(expenditure, X1:X3, remove=FALSE)
ggplot(expenditure, aes(x=X, y=Y))+
geom_point()
X <- unite(expenditure, X1:X3, remove=FALSE)
rlang::last_error()
unite(expenditure, sep="X", X1:X3, remove=TRUE)
unite(expenditure, sep="X", X1:X3)
("X", X1:X3, remove=FALSE)
expenditure %>% unite("X", X1:X3, remove=FALSE)
ggplot(expenditure, aes(x=X, y=Y))+
geom_point()
expenditure %>% unite("X", X1:X3, remove=FALSE)
ggplot(expenditure, aes(x=X, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X, y=Y))+
geom_point()
new_exp <- expenditure %>% unite("X", X1:X3, remove=FALSE)
ggplot(new_exp, aes(x=X, y=Y))+
geom_point()
ggplot(expenditure, aes(x=Region, y=Y))+
geom_point()
expenditure <- read.table("expenditure.txt", header=T)
str(expenditure)
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X2, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X3, y=Y))+
geom_point()
ggplot(expenditure, aes(x=Region, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y, color=Region))+
geom_point()
#####################
# load libraries
# set wd
# clear global .envir
#####################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
library(tidyr)
library(dplyr)
library(ggplot2)
lapply(c(),  pkgTest)
# set working directory
setwd("~/GitHub/QTM200Spring2020/problem_sets/PS1")
#####################
# Problem 1
#####################
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
##finding the confidnce interval
#first the mean was found
m <- mean(y)
#then the standard deviation
s <- sd(y)
#n is the number of samples
n <- 25
#finding the error using t distribution as n is less than 30
error <- qt(0.95, df=n-1)*s/sqrt(n)
#left confidence interval
left <- m-error
#right confidence interval
right <- m+error
left
right
# the 90% CI is (93.96, 102.92)
#####################
# Problem 2
#####################
#Conducting a test with 0.05 significance level
#assumptions are: continous data, random sample, the sample size is bigger (shown through formula)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
#null hypothesis Ho: pi < pio
pio <- 100
pi <- mean(y)
ts <- qt(.95, df=n-1)*s/sqrt(n)
ts
p = pt(abs(ts), df=n-1, lower.tail=F)
p
#the p value is well below the threshold of 0.05, therefore you reject the null and state that the average IQ of the students in her school is equal or higher to the average IQ score among all the schools in the country.
#####################
# Problem 3
#####################
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
expenditure <- read.table("expenditure.txt", header=T)
str(expenditure)
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X2, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X3, y=Y))+
geom_point()
ggplot(expenditure, aes(x=Region, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y, color=Region))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X2, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X3, y=Y))+
geom_point()
pi <- mean(y)
pi
#####################
# Problem 2
#####################
#Conducting a test with 0.05 significance level
#assumptions are: continous data, random sample, the sample size is bigger (shown through formula)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
pi <- mean(y)
pi
pi <- mean(y)
pi
ts <- qt(.95, df=n-1)*s/sqrt(n)
ts
p = pt(abs(ts), df=n-1, lower.tail=F)
p
install.packages("TikzDevice")
install.packages("tikzDevice")
#####################
# load libraries
# set wd
# clear global .envir
#####################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
library(tidyr)
library(dplyr)
library(ggplot2)
library(tikzDevice)
lapply(c(),  pkgTest)
# set working directory
setwd("~/GitHub/QTM200Spring2020/problem_sets/PS1")
#####################
# Problem 1
#####################
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
##finding the confidnce interval
#first the mean was found
m <- mean(y)
#then the standard deviation
s <- sd(y)
#n is the number of samples
n <- 25
#finding the error using t distribution as n is less than 30
error <- qt(0.95, df=n-1)*s/sqrt(n)
#left confidence interval
left <- m-error
#right confidence interval
right <- m+error
left
right
# the 90% CI is (93.96, 102.92)
#####################
# Problem 2
#####################
#Conducting a test with 0.05 significance level
#assumptions are: continous data, random sample, the sample size is bigger (shown through formula)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
#null hypothesis Ho: pi < pio
pio <- 100
pi <- mean(y)
pi
ts <- qt(.95, df=n-1)*s/sqrt(n)
ts
p = pt(abs(ts), df=n-1, lower.tail=F)
p
#the p value is well below the threshold of 0.05, therefore you reject the null and state that the average IQ of the students in her school is equal or higher to the average IQ score among all the schools in the country.
#####################
# Problem 3
#####################
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
expenditure <- read.table("expenditure.txt", header=T)
str(expenditure)
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X2, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X3, y=Y))+
geom_point()
ggplot(expenditure, aes(x=Region, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y, color=Region))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
#####################
# load libraries
# set wd
# clear global .envir
#####################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
library(tidyr)
library(dplyr)
library(ggplot2)
library(tikzDevice)
lapply(c(),  pkgTest)
# set working directory
setwd("~/GitHub/QTM200Spring2020/problem_sets/PS1")
#####################
# Problem 1
#####################
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
##finding the confidnce interval
#first the mean was found
m <- mean(y)
#then the standard deviation
s <- sd(y)
#n is the number of samples
n <- 25
#finding the error using t distribution as n is less than 30
error <- qt(0.95, df=n-1)*s/sqrt(n)
#left confidence interval
left <- m-error
#right confidence interval
right <- m+error
left
right
# the 90% CI is (93.96, 102.92)
#####################
# Problem 2
#####################
#Conducting a test with 0.05 significance level
#assumptions are: continous data, random sample, the sample size is bigger (shown through formula)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
#null hypothesis Ho: pi < pio
pio <- 100
pi <- mean(y)
pi
ts <- qt(.95, df=n-1)*s/sqrt(n)
ts
p = pt(abs(ts), df=n-1, lower.tail=F)
p
#the p value is well below the threshold of 0.05, therefore you reject the null and state that the average IQ of the students in her school is equal or higher to the average IQ score among all the schools in the country.
#####################
# Problem 3
#####################
y <- c(1, 2, 1, 3, 4, 1, 1, 4, 2, 1, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 1, 3, 4)
expenditure <- read.table("expenditure.txt", header=T)
str(expenditure)
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X2, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X3, y=Y))+
geom_point()
ggplot(expenditure, aes(x=Region, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y, color=Region))+
geom_point()
ggplot(expenditure, aes(x=X2, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X3, y=Y))+
geom_point()
ggplot(expenditure, aes(x=Region, y=Y))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y, color=Region, shape=Region))+
geom_point()
data$region[data$Region=1] <- "1"
data$region[data$Region=2] <-"2"
data$region[data$Region <=2] <-"2"
ggplot(expenditure, aes(x=X1, y=Y, color=Region, group=Region))+
geom_point()
ggplot(expenditure, aes(x=X1, y=Y, color=Region, group=Region))+
geom_point(aes(shape=Region))
str(expenditure)
typeof(expenditure$Region)
expenditure[,'Region'] <- factor(expenditure[,'Region'])
class(expenditure$Region)
ggplot(expenditure, aes(x=X1, y=Y, color=Region, group=Region))+
geom_point(aes(shape=Region))
#####################
# Problem 2
#####################
#Conducting a test with 0.05 significance level
#assumptions are: continous data, random sample, the sample size is bigger (shown through formula)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
ts
##finding the confidnce interval
#first the mean was found
m <- mean(y)
#then the standard deviation
s <- sd(y)
s
m
#finding the error using t distribution as n is less than 30
error <- qt(0.95, df=n-1)*s/sqrt(n)
error
=======
expenditure <- read.table("expenditure.txt", header=T)
#Please plot the reltionships among Y, X1, X2, and X3.
#Plot Y
expenditure$Y
hist(expenditure$Y, main="Per Capita Expenditure on Public Education", xlab="Y", ylab="Frequency")
#Plot X1
hist(expenditure$X1, main="Per Capita Personal Income", xlab="X1", ylab="Frequency")
#Plot X2
hist(expenditure$X2, main="Number of Residents per Thousand Under 18 Years", xlab="X2", ylab="Frequency")
#Reproduce the above graph adding region and display different regions with different colors/symbols.
plot(expenditure$Y, expenditure$X1, col=as.integer(expenditure$Region), pch=as.integer(expenditure$Region), main = "Public Education Expenditure & Personal Income Per Capita by Region", xlab="Y", ylab="X1")
>>>>>>> upstream/master
